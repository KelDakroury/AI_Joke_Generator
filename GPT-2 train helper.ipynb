{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from glob import glob\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "\n",
    "# Eng\n",
    "\n",
    "qa_jokes_filepath = os.path.join('data', 'qa_jokes.csv')\n",
    "short_jokes_filepath = os.path.join('data', 'short_jokes.csv')\n",
    "transcripts_path = os.path.join('data', 'transcripts')\n",
    "\n",
    "qa_jokes_prep_outpath = os.path.join('data', 'prep', 'qa_jokes_gpt2.txt')\n",
    "short_jokes_prep_outpath = os.path.join('data', 'prep', 'short_jokes_gpt2.txt')\n",
    "transcripts_prep_outpath = os.path.join('data', 'prep', 'transcripts_gpt2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_encoding(s):\n",
    "    \"\"\"Skip characters that can't be encoded by standard encoder.\"\"\"\n",
    "    return s.encode('utf-8', 'ignore').decode('utf8', 'ignore')\n",
    "\n",
    "# TODO: Add &amp;nbsp;  &gt;  &lt;\n",
    "regexps = [ # Regexp for the special chars\n",
    "    (re.compile('â™¦'), '*'),\n",
    "    (re.compile('\\n *\\n'), '\\n'), # Replace multiple newlines with one\n",
    "    (re.compile(r' {2,}'), ' '), # Replace multiple spaces with one\n",
    "]\n",
    "\n",
    "def fix_text(s):\n",
    "    for regexp in regexps:\n",
    "        s = regexp[0].sub(regexp[1], s)\n",
    "    return fix_encoding(s.strip())\n",
    "\n",
    "def write_to_file(file_path, text, encoding=None):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w', encoding=encoding) as out_file:\n",
    "        out_file.write(text)\n",
    "\n",
    "START_DOC_TOKEN = ''\n",
    "END_DOC_TOKEN = '<|endoftext|>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA Jokes\n",
    "Taken from [here](https://www.kaggle.com/jiriroz/qa-jokes).\n",
    "\n",
    "Cleaned from noisy/non-represantable data. (Notes, already inserted \"Q\"/\"A\" tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38232 entries, 0 to 38231\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   ID        38232 non-null  int64 \n",
      " 1   Question  38232 non-null  object\n",
      " 2   Answer    38232 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 896.2+ KB\n"
     ]
    }
   ],
   "source": [
    "qa_jokes = pd.read_csv(qa_jokes_filepath)\n",
    "qa_jokes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_corpus = []\n",
    "for _, question, answer in qa_jokes.values:\n",
    "    qa_corpus.append(f'{START_DOC_TOKEN}[QUESTION] {question}\\n[ANSWER] {answer}\\n{END_DOC_TOKEN}')\n",
    "\n",
    "qa_corpus = '\\n'.join(map(lambda s: fix_text(s), qa_corpus))\n",
    "\n",
    "write_to_file(qa_jokes_prep_outpath, qa_corpus, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcripts\n",
    "Scrapped dataset of stand up's transcripts from [scrapsfromtheloft.com](scrapsfromtheloft.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Jokes\n",
    "Dataset taken from [here](https://www.kaggle.com/abhinavmoudgil95/short-jokes).\n",
    "\n",
    "Also cleaned up. (Twitter tags, f@ck/@sshole words, samples with link to smth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 230974 entries, 0 to 230973\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   ID      230974 non-null  int64 \n",
      " 1   Joke    230974 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "short_jokes = pd.read_csv('/home/karim/Documents/Studies/NLP/Project/data/short_jokes.csv')\n",
    "short_jokes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find QA jokes in short jokes\n",
    "from nltk.tokenize import sent_tokenize\n",
    "qa_jokes_in_short_jokes = []\n",
    "for i, (_, joke) in enumerate(short_jokes.values):\n",
    "    sentences = sent_tokenize(joke.strip())\n",
    "    if len(sentences) < 4 and len(sentences) > 1 and sentences[0][-1] == '?':\n",
    "        qa_jokes_in_short_jokes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What's the difference between a job and a wife? After 10 years, a job still sucks!\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show random one\n",
    "ind = np.random.randint(len(qa_jokes_in_short_jokes))\n",
    "short_jokes.iloc[qa_jokes_in_short_jokes[ind]].Joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "ID                                                 201384\n",
      "Joke    What's the difference between a job and a wife...\n",
      "Name: 200799, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(type(short_jokes.iloc[qa_jokes_in_short_jokes[ind]]))\n",
    "print(short_jokes.iloc[qa_jokes_in_short_jokes[ind]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qa_jokes_in_short_jokes)\n",
    "print(ind)\n",
    "short_jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201384 What's the difference between a job and a wife? After 10 years, a job still sucks!\n"
     ]
    }
   ],
   "source": [
    "x, y = short_jokes.iloc[qa_jokes_in_short_jokes[ind]]\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add them to qa jokes\n",
    "for i, joke in short_jokes.iloc[qa_jokes_in_short_jokes].values:\n",
    "    sentences = sent_tokenize(joke.strip())\n",
    "    question, answer = sentences[0], ' '.join(sentences[1:])\n",
    "    qa_corpus += fix_encoding(f'{START_DOC_TOKEN}[QUESTION] {question}\\n[ANSWER] {answer}\\n{END_DOC_TOKEN}\\n')\n",
    "\n",
    "write_to_file(qa_jokes_prep_outpath, qa_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete found qa in short\n",
    "short_jokes = short_jokes.drop(qa_jokes_in_short_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_jokes_corpus = ''\n",
    "for i, joke in short_jokes.values:\n",
    "    short_jokes_corpus += fix_encoding(f'{START_DOC_TOKEN}{joke.strip()}\\n{END_DOC_TOKEN}\\n')\n",
    "\n",
    "\n",
    "write_to_file(short_jokes_prep_outpath, short_jokes_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cmd_command(python_path, script, kwargs, flags):\n",
    "    args = ' '.join(f'--{k}={v}' for k, v in kwargs.items())\n",
    "    args += ' ' + ' '.join(f'--{f}' for f in flags)\n",
    "    return f'{python_path} {script} {args}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_path = r'python3'\n",
    "script = r'run_lm_finetuning.py'\n",
    "train_kwargs = {\n",
    "    'model_type': 'gpt2', # gpt2, ctrl, openai-gpt, xlnet, transfo-xl, xlm\n",
    "    'model_name_or_path':'gpt2',\n",
    "    'output_dir':'output',\n",
    "    'block_size': 512,\n",
    "    'learning_rate': 1e-6,\n",
    "    'num_train_epochs': 3,\n",
    "    'per_gpu_train_batch_size': 2,\n",
    "    'gradient_accumulation_steps': 8,\n",
    "    'save_steps': 1000,\n",
    "#     'max_steps': 20000,\n",
    "}\n",
    "\n",
    "# set CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "train_outputs = [\n",
    "    'gpt2',\n",
    "    'output',   # Transcripts 1e-6, 5 grad_acc 4\n",
    "    'output_1', # Transcripts 1e-5, 2 grad_acc 8\n",
    "    'output_2', # short_jokes 1e-5, 2 grad_acc 8\n",
    "    'output_3', # short_jokes 1e-6, 5 grad_acc 8\n",
    "    'output_4', # short_jokes 1e-7, 2 grad_acc 2\n",
    "    'output_5', # qa_jokes    1e-5, 3 grad_acc 8 - most funny yet\n",
    "    'output_6', # qa_jokes    1e-5, 3 grad_acc 4\n",
    "    'output_7', # qa_jokes    1e-6, 2 grad_acc 2\n",
    "    'output_8', # qa_jokes    1e-6, 10 grad_acc 8\n",
    "    \n",
    "]\n",
    "\n",
    "train_flags = [\n",
    "    'do_train',\n",
    "    'overwrite_output_dir',\n",
    "#     'fp16',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_kwargs['train_data_file'] = transcripts_prep_outpath\n",
    "# train_kwargs['train_data_file'] = short_jokes_prep_outpath\n",
    "train_kwargs['train_data_file'] = qa_jokes_prep_outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: gpt2 \n",
      "To: models/output\n"
     ]
    }
   ],
   "source": [
    "train_kwargs['model_name_or_path'] = train_outputs[0]\n",
    "# train_kwargs['model_name_or_path'] = os.path.join('models', train_outputs[0])\n",
    "train_kwargs['output_dir'] = os.path.join('models', train_outputs[1])\n",
    "print('From:', train_kwargs['model_name_or_path'], '\\nTo:', train_kwargs['output_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 run_lm_finetuning.py --model_type=gpt2 --model_name_or_path=gpt2 --output_dir=models/output --block_size=512 --learning_rate=1e-06 --num_train_epochs=3 --per_gpu_train_batch_size=2 --gradient_accumulation_steps=8 --save_steps=1000 --train_data_file=data/prep/qa_jokes_gpt2.txt --do_train --overwrite_output_dir\n"
     ]
    }
   ],
   "source": [
    "cmd_command = create_cmd_command(python_path, script, train_kwargs, train_flags)\n",
    "print(cmd_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 run_generation.py --model_type=gpt2 --model_name_or_path=models/output --prompt=\"[QUESTION]\" --length=100 --stop_token=\"<|endoftext|>\" --temperature=0.9 --repetition_penalty=1.05 --k=50 --p=0.95 --num_return_sequences=40 \n"
     ]
    }
   ],
   "source": [
    "gen_script = r'run_generation.py'\n",
    "generate_kwargs = {\n",
    "    'model_type': train_kwargs['model_type'],\n",
    "    'model_name_or_path': train_kwargs['output_dir'],\n",
    "    'prompt': rf'\"{START_DOC_TOKEN}[QUESTION]\"',\n",
    "#     'prompt': '\"The reddit enters a bar\"',\n",
    "    'length': 100,\n",
    "    'stop_token': f'\"{END_DOC_TOKEN}\"',\n",
    "    'temperature': 0.9, # temperature of 1.0 has no effect, lower tend toward greedy sampling\n",
    "    'repetition_penalty': 1.05, # primarily useful for CTRL model; in that case, use 1.2\n",
    "    'k': 50,\n",
    "    'p': 0.95,\n",
    "#     'padding_text': '', # Padding text for Transfo-XL and XLNet.\n",
    "    'num_return_sequences':40,\n",
    "}\n",
    "gen_flags = []\n",
    "\n",
    "cmd_command = create_cmd_command(python_path, gen_script, generate_kwargs, gen_flags)\n",
    "print(cmd_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
